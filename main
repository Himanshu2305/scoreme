from pdfminer.high_level import extract_pages
from pdfminer.layout import LTTextContainer, LTTextLine


import logging
logging.getLogger("pdfminer").setLevel(logging.ERROR)

def extract_text_elements(pdf_path):
    elements = []
    try:
        for page_num, page_layout in enumerate(extract_pages(pdf_path)):
            try:
                for element in page_layout:
                    if isinstance(element, LTTextContainer):
                        for text_line in element:
                            if isinstance(text_line, LTTextLine):
                                try:
                                    x0, y0, x1, y1 = text_line.bbox
                                    text = text_line.get_text().strip()
                                    if text:
                                        elements.append({
                                            "text": text,
                                            "x0": x0,
                                            "x1": x1,
                                            "y0": y0,
                                            "y1": y1,
                                            "page": page_num + 1
                                        })
                                except Exception as e:
                                    print(f" Skipped unreadable text line on page {page_num + 1}: {e}")
            except Exception as e:
                print(f"Skipped entire page {page_num + 1} due to error: {e}")
    except Exception as e:
        print(f" Could not open PDF: {e}")

    return elements

# table_detector.py
from collections import defaultdict

def detect_table_rows(elements, y_tolerance=5):
    tables_by_page = defaultdict(list)
    for element in elements:
        page = element["page"]
        tables_by_page[page].append(element)

    all_tables = []

    for page, elements in tables_by_page.items():
        rows = defaultdict(list)
        for element in elements:
            matched = False
            for y in rows:
                if abs(y - element["y0"]) < y_tolerance:
                    rows[y].append(element)
                    matched = True
                    break
            if not matched:
                rows[element["y0"]].append(element)

        sorted_rows = sorted(rows.items(), key=lambda r: -r[0])
        table = []
        for _, row_elements in sorted_rows:
            sorted_cells = sorted(row_elements, key=lambda el: el["x0"])
            table.append([el["text"] for el in sorted_cells])

        all_tables.append({
            "page": page,
            "table": table
        })

    return all_tables


def normalize_rows(rows):
    max_cols = max(len(row) for row in rows)
    normalized = [row + [""] * (max_cols - len(row)) for row in rows]
    return pd.DataFrame(normalized)

def save_table_to_excel(tables, excel_path):
    with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
        for idx, table in enumerate(tables):
            sheet_name = f"Page{table['page']}_Table{idx + 1}"
            df = normalize_rows(table["table"])
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    print(f"Saved tables to: {excel_path}")


elements = extract_text_elements("sample.pdf")
if not elements:
    print("No extractable text found.")
else:
    tables = detect_table_rows(elements)
    if not tables:
        print(" No tables detected. Still writing empty Excel file.")
        # Write an empty sheet
        import pandas as pd
        with pd.ExcelWriter("output.xlsx", engine="openpyxl") as writer:
            pd.DataFrame([["No tables extracted"]]).to_excel(writer, index=False, sheet_name="Summary")
    else:
        save_table_to_excel(tables, "output.xlsx")

print(" Done. Output file saved: output.xlsx")
